<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache SkyWalking – Tracing</title>
    <link>/tags/tracing/</link>
    <description>Recent content in Tracing on Apache SkyWalking</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 16 Mar 2021 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/tags/tracing/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Blog: SourceMarker: Continuous Feedback for Developers</title>
      <link>/blog/2021-03-16-continuous-feedback/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/2021-03-16-continuous-feedback/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;SM_IDE-APM.gif&#34; alt=&#34;Alt Text&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sourcemarker.dev&#34;&gt;SourceMarker&lt;/a&gt; is an open-source continuous feedback IDE plugin built on top of Apache SkyWalking, a popular open-source APM system with monitoring, tracing, and diagnosing capabilities for distributed software systems. SkyWalking, a truly holistic system, provides the means for automatically producing, storing, and querying software operation metrics. It requires little to no code changes to implement and is lightweight enough to be used in production. By itself, SkyWalking is a formidable force in the realm of continuous monitoring technology.&lt;/p&gt;
&lt;p&gt;SourceMarker, leveraging the continuous monitoring functionality provided by SkyWalking, creates continuous feedback technology by automatically linking software operation metrics to source code and displaying feedback directly inside of the IDE. While currently only supporting JetBrains-based IDEs and JVM-based programming languages, SourceMarker may be extended to support any number of programming languages and IDEs. Using SourceMarker, software developers can understand and validate software operation inside of their IDE. Instead of charts that indicate the health of the application, software developers can view the health of individual source code components and interpret software operation metrics from a much more familiar perspective. Such capabilities improve productivity as time spent continuously context switching from development to monitoring would be eliminated.&lt;/p&gt;
&lt;h2 id=&#34;logging&#34;&gt;Logging&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;SM_Logging.gif&#34; alt=&#34;Logging&#34;&gt;&lt;/p&gt;
&lt;p&gt;The benefits of continuous feedback technology are immediately apparent with the ability to view and search logs directly from source code. Instead of tailing log files or viewing logs through the browser, SourceMarker allows software developers to navigate production logs just as easily as they navigate source code. By using the source code as the primary perspective for navigating logs, SourceMarker allows software developers to view logs specific to any package, class, method, or line directly from the context of the source code which resulted in those logs.&lt;/p&gt;
&lt;h2 id=&#34;tracing&#34;&gt;Tracing&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;SM_Tracing.gif&#34; alt=&#34;Tracing&#34;&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, continuous feedback technology offers software developers a deeper understanding of software by explicitly tying the implicit software operation to source code. Instead of visualizing software traces as Gantt charts, SourceMarker allows software developers to step through trace stacks while automatically resolving trace tags and logs. With SourceMarker, software developers can navigate production software traces in much the same way one debugs local applications.&lt;/p&gt;
&lt;h2 id=&#34;alerting&#34;&gt;Alerting&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;SM_Alerting.gif&#34; alt=&#34;Alerting&#34;&gt;&lt;/p&gt;
&lt;p&gt;Most importantly, continuous feedback technology keeps software developers aware of production software operation. Armed with an APM-powered IDE, every software developer can keep track of the behavior of any method, class, package, and even the entire application itself. Moreover, this allows for source code to be the medium through which production bugs are made evident, thereby creating the feasibility of source code with the ability to self-diagnose and convey its own health.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;download-sourcemarker&#34;&gt;Download SourceMarker&lt;/h1&gt;
&lt;p&gt;SourceMarker aims to bridge the theoretical and empirical practices of software development through continuous feedback. The goal is to make developing software with empirical data feel natural and intuitive, creating more complete software developers that understand the entire software development cycle.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sourceplusplus/sourcemarker&#34;&gt;https://github.com/sourceplusplus/sourcemarker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This project is still early in its development, so if you think of any ways to improve SourceMarker, please let us know.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: Apache SkyWalking: How to propagate context between threads when using ThreadPoolExecutor</title>
      <link>/blog/2021-02-09-skywalking-trace-threadpool/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/2021-02-09-skywalking-trace-threadpool/</guid>
      <description>
        
        
        &lt;p&gt;When using SkyWalking java agent, people usually propagate context easily. They even do not need to change the business
code. However, it becomes harder when you want to propagate context between threads when using ThreadPoolExecutor.
You can use the RunnableWrapper in the maven artifact org.apache.skywalking:apm-toolkit-trace. This way you must change
your code. The developer manager usually don&amp;rsquo;t like this because there may be lots of projects, or lots of runnable code.
If they don&amp;rsquo;t use SkyWalking some day, the code added will be superfluous and inelegant.&lt;/p&gt;
&lt;p&gt;Is there a way to propagate context without changing the business code? Yes.&lt;/p&gt;
&lt;p&gt;Skywalking java agent enhances a class by add a field and implement an interface. The ThreadPoolExecutor is a special
class that is used widely. We even don&amp;rsquo;t know when and where it is loaded. Most JVMs do not allow changes in the class
file format for classes that have been loaded previously. So SkyWalking should not enhance the ThreadPoolExecutor successfully by retransforming when the ThreadPoolExecutor has been loaded.
However, we can apply advice to the ThreadPoolExecutor#execute method and wrap the Runnable param using our
own agent, then enhance the wrapper class by SkyWalking java agent. An advice do not change the layout of a class.&lt;/p&gt;
&lt;p&gt;Now we should decide how to do this. You can use the RunnableWrapper in the maven artifact
org.apache.skywalking:apm-toolkit-trace to wrap the param, but you need to face another problem. This RunnableWrapper
has a plugin whose active condition is checking if there is @TraceCrossThread. Agent core uses net.bytebuddy.pool.TypePool.Default.WithLazyResolution.LazyTypeDescription to find the annotations
of a class. The LazyTypeDescription finds annotations by using a URLClassLoader with no urls if the classloader is
null(bootstrap classloader). So it can not find the @TraceCrossThread class unless you change the LocationStrategy of
SkyWalking java agent builder.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://github.com/libinglong/skywalking-threadpool-agent&#34;&gt;this project&lt;/a&gt;, I write my own wrapper class,
and simply add a plugin with a name match condition.
Next, Let me show you how these two agents work together.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Move the plugin to the skywalking &amp;ldquo;plugins&amp;rdquo; directory.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plugin.png&#34; alt=&#34;plugin&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;sky-plugins.png&#34; alt=&#34;plugins directory&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add this agent after the SkyWalking agent since the wrapper class should not be loaded before
SkyWalking agent instrumentation have finished. For example,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;java -javaagent:/path/to/skywalking-agent.jar -javaagent:/path/to/skywalking-tool-agent-v1.0.0.jar &amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;agent.png&#34; alt=&#34;agent.png&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When our application runs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SkyWalking java agent adds a transformer by parsing the plugin for enhancing the wrapper class in the tool agent.&lt;/li&gt;
&lt;li&gt;The tool agent loads the wrapper class into bootstrap classloader. This triggers the previous transformer.&lt;/li&gt;
&lt;li&gt;The tool agent applies an advice to the ThreadPoolExecutor class, wrapping the java.lang.Runnable param of &amp;ldquo;execute&amp;rdquo; method with the wrapper class.&lt;/li&gt;
&lt;li&gt;Now SkyWalking propagates the context with the wrapper class.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enjoy tracing with ThreadPoolExecutor in SkyWalking!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: Apache SkyWalking: Use Profiling to Fix the Blind Spot of Distributed Tracing</title>
      <link>/blog/2020-04-13-apache-skywalking-profiling/</link>
      <pubDate>Mon, 13 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020-04-13-apache-skywalking-profiling/</guid>
      <description>
        
        
        &lt;p&gt;&lt;em&gt;This post originally appears on &lt;a href=&#34;https://thenewstack.io/apache-skywalking-use-profiling-to-fix-the-blind-spot-of-distributed-tracing/&#34;&gt;The New Stack&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This post introduces a way to automatically profile code in production with &lt;a href=&#34;https://skywalking.apache.org&#34;&gt;Apache SkyWalking&lt;/a&gt;. We believe the profile method helps reduce maintenance and overhead while increasing the precision in root cause analysis.&lt;/p&gt;
&lt;h3 id=&#34;limitations-of-the-distributed-tracing&#34;&gt;Limitations of the Distributed Tracing&lt;/h3&gt;
&lt;p&gt;In the early days, metrics and logging systems were the key solutions in monitoring platforms. With the adoption of microservice and distributed system-based architecture, distributed tracing has become more important. Distributed tracing provides relevant service context, such as system topology map and RPC parent-child relationships.&lt;/p&gt;
&lt;p&gt;Some claim that distributed tracing is the best way to discover the cause of performance issues in a distributed system. It’s good at finding issues at the RPC abstraction, or in the scope of components instrumented with spans. However, it isn’t that perfect.&lt;/p&gt;
&lt;p&gt;Have you been surprised to find a span duration longer than expected, but no insight into why? What should you do next? Some may think that the next step is to add more instrumentation, more spans into the trace, thinking that you would eventually find the root cause, with more data points. We’ll argue this is not a good option within a production environment. Here’s why:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There is a risk of application overhead and system overload. Ad-hoc spans measure the performance of specific scopes or methods, but picking the right place can be difficult. To identify the precise cause, you can “instrument” (add spans to) many suspicious places. The additional instrumentation costs more CPU and memory in the production environment. Next, ad-hoc instrumentation that didn’t help is often forgotten, not deleted. This creates a valueless overhead load. In the worst case, excess instrumentation can cause performance problems in the production app or overload the tracing system.&lt;/li&gt;
&lt;li&gt;The process of ad-hoc (manual) instrumentation usually implies at least a restart. Trace instrumentation libraries, like Zipkin Brave, are integrated into many framework libraries. To instrument a method’s performance typically implies changing code, even if only an annotation. This implies a re-deploy. Even if you have the way to do auto instrumentation, like Apache SkyWalking, you still need to change the configuration and reboot the app. Otherwise, you take the risk of GC caused by hot dynamic instrumentation.&lt;/li&gt;
&lt;li&gt;Injecting instrumentation into an uninstrumented third party library is hard and complex. It takes more time and many won’t know how to do this.&lt;/li&gt;
&lt;li&gt;Usually, we don’t have code line numbers in the distributed tracing. Particularly when lambdas are in use, it can be difficult to identify the line of code associated with a span.
Regardless of the above choices, to dive deeper requires collaboration with your Ops or SRE team, and a shared deep level of knowledge in distributed tracing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Regardless of the above choices, to dive deeper requires collaboration with your Ops or SRE team, and a shared deep level of knowledge in distributed tracing.&lt;/p&gt;
&lt;h3 id=&#34;profiling-in-production&#34;&gt;Profiling in Production&lt;/h3&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;To reuse distributed tracing to achieve method scope precision requires an understanding of the above limitations and a different approach. We called it PROFILE.&lt;/p&gt;
&lt;p&gt;Most high-level languages build and run on a thread concept. The profile approach takes continuous thread dumps. We merge the thread dumps to estimate the execution time of every method shown in the thread dumps. The key for distributed tracing is the tracing context, identifiers active (or current) for the profiled method. Using this trace context, we can weave data harvested from profiling into existing traces. This allows the system to automate otherwise ad-hoc instrumentation. Let’s dig deeper into how profiling works:&lt;/p&gt;
&lt;p&gt;We consider a method invocation with the same stack depth and signature (method, line number etc), the same operation. We derive span timestamps from the thread dumps the same operation is in. Let’s put this visually:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;skywalking-blindspot-1.png&#34; alt=&#34;span timespaces&#34;&gt;&lt;/p&gt;
&lt;p&gt;Above, represents 10 successive thread dumps. If this method is in dumps 4-8, we assume it started before dump 4 and finished after dump 8. We can’t tell exactly when the method started and stopped. but the timestamps of thread dumps are close enough.&lt;/p&gt;
&lt;p&gt;To reduce overhead caused by thread dumps, we only profile methods enclosed by a specific entry point, such as a URI or MVC Controller method. We identify these entry points through the trace context and the APM system.&lt;/p&gt;
&lt;p&gt;The profile does thread dump analysis and gives us:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The root cause, precise to the line number in the code.&lt;/li&gt;
&lt;li&gt;Reduced maintenance as ad-hoc instrumentation is obviated.&lt;/li&gt;
&lt;li&gt;Reduced overload risk caused by ad-hoc instrumentation.&lt;/li&gt;
&lt;li&gt;Dynamic activation: only when necessary and with a very clear profile target.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;implementing-precise-profiling-with-apache-skywalking-7&#34;&gt;Implementing Precise Profiling with Apache SkyWalking 7&lt;/h3&gt;
&lt;p&gt;Distributed profiling is built-into Apache SkyWalking application performance monitoring (APM). Let’s demonstrate how the profiling approach locates the root cause of the performance issue.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;final CountDownLatchcountDownLatch= new CountDownLatch(2);
 
threadPool.submit(new Task1(countDownLatch));
threadPool.submit(new Task2(countDownLatch));
 
try {
   countDownLatch.await(500, TimeUnit.MILLISECONDS);
} catch (InterruptedExceptione) {
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Task1 and Task2 have a race condition and unstable execution time: they will impact the performance of each other and anything calling them. While this code looks suspicious, it is representative of real life. People in the OPS/SRE team are not usually aware of all code changes and who did them. They only know something in the new code is causing a problem.&lt;/p&gt;
&lt;p&gt;To make matters interesting, the above code is not always slow: it only happens when the condition is locked. In SkyWalking APM, we have metrics of endpoint p99/p95 latency, so, we are easy to find out the p99 of this endpoint is far from the avg response time. However, this is not the same as understanding the cause of the latency. To locate the root cause, add a profile condition to this endpoint: duration greater than 500ms. This means faster executions will not add profiling load.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;skywalking-blindspot-2.png&#34; alt=&#34;profiled segment&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is a typical profiled trace segment (part of the whole distributed trace) shown on the SkyWalking UI. We now notice the “service/processWithThreadPool” span is slow as we expected, but why? This method is the one we added the faulty code to. As the UI shows that method, we know the profiler is working. Now, let’s see what the profile analysis result say.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;skywalking-blindspot-3.png&#34; alt=&#34;profile analysis&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is the profile analysis stack view. We see the stack element names, duration (include/exclude the children) and slowest methods have been highlighted. It shows clearly, “sun.misc.Unsafe.park” costs the most time. If we look for the caller, it is the code we added: &lt;strong&gt;CountDownLatch.await&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-limitations-of-the-profile-method&#34;&gt;The Limitations of the Profile Method&lt;/h3&gt;
&lt;p&gt;No diagnostic tool can fit all cases, not even the profile method.&lt;/p&gt;
&lt;p&gt;The first consideration is mistaking a repeatedly called method for a slow method. Thread dumps are periodic. If there is a loop of calling one method, the profile analysis result would say the target method is slow because it is captured every time in the dump process. There could be another reason. A method called many times can also end up captured in each thread dump. Even so, the profile did what it is designed for. It still helps the OPS/SRE team to locate the code having the issue.&lt;/p&gt;
&lt;p&gt;The second consideration is overhead, the impact of repeated thread dumps is real and can’t be ignored. In SkyWalking, we set the profile dump period to at least 10ms. This means we can’t locate method performance issues if they complete in less than 10ms. SkyWalking has a threshold to control the maximum parallel degree as well.&lt;/p&gt;
&lt;p&gt;Understanding the above keeps distributed tracing and APM systems useful for your OPS/SRE team.&lt;/p&gt;
&lt;h3 id=&#34;how-to-try-this&#34;&gt;How to Try This&lt;/h3&gt;
&lt;p&gt;Everything we discussed, including the Apache SkyWalking Java Agent, profile analysis code, and UI, could be found in our GitHub repository. We hope you enjoyed this new profile method, and love Apache SkyWalking. If so, &lt;a href=&#34;https://github.com/apache/skywalking&#34;&gt;give us a star on GitHub&lt;/a&gt; to encourage us.&lt;/p&gt;
&lt;p&gt;SkyWalking 7 has just been released. You can contact the project team through the following channels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Follow &lt;a href=&#34;https://twitter.com/ASFSkyWalking&#34;&gt;SkyWalking twitter&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Subscribe mailing list: &lt;a href=&#34;mailto:dev@skywalking.apache.org&#34;&gt;dev@skywalking.apache.org&lt;/a&gt;. Send to &lt;a href=&#34;mailto:dev-subscribe@kywalking.apache.org&#34;&gt;dev-subscribe@kywalking.apache.org&lt;/a&gt; to subscribe to the mail list.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Co-author Sheng Wu is a Tetrate founding engineer and the founder and VP of Apache SkyWalking. He is solving the problem of observability for large-scale service meshes in hybrid and multi-cloud environments.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Adrian Cole works in the Spring Cloud team at VMware, mostly on Zipkin&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Han Liu is a tech expert at Lagou. He is an Apache SkyWalking committer&lt;/em&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: Understand distributed trace easier in the incoming 6-GA</title>
      <link>/blog/2019-01-01-understand-trace/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019-01-01-understand-trace/</guid>
      <description>
        
        
        &lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;Distributed tracing is a necessary part of modern microservices architecture, but how to understand or use distributed tracing data is unclear to some end users. This blog overviews typical distributed tracing use cases with new visualization features in SkyWalking v6. We hope new users will understand more through these examples.&lt;/p&gt;
&lt;h2 id=&#34;metric-and-topology&#34;&gt;Metric and topology&lt;/h2&gt;
&lt;p&gt;Trace data underpins in two well known analysis features: &lt;strong&gt;metric&lt;/strong&gt; and &lt;strong&gt;topology&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Metric&lt;/strong&gt; of each service, service instance, endpoint are derived from entry spans in trace. Metrics represent response time performance. So, you could have average response time, 99% response time, success rate, etc. These are broken down by service, service instance, endpoint.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Topology&lt;/strong&gt; represents links between services and is distributed tracing&amp;rsquo;s most attractive feature. Topologies allows all users to understand distributed service relationships and dependencies even when they are varied or complex. This is important as it brings a single view to all interested parties, regardless of if they are a developer, designer or operator.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example topology of 4 projects, including Kafka and two outside dependencies.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./demo-spring.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;Topology in SkyWalking optional UI, RocketBot&lt;/p&gt;
&lt;h2 id=&#34;trace&#34;&gt;Trace&lt;/h2&gt;
&lt;p&gt;In a distributed tracing system, we spend a lot of resources(CPU, Memory, Disk and Network) to generate, transport and persistent trace data. Let&amp;rsquo;s try to answer why we do this? What are the typical diagnosis and system performance questions we can answer with trace data?&lt;/p&gt;
&lt;p&gt;SkyWalking v6 includes two trace views:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;TreeMode: The first time provided. Help you easier to identify issues.&lt;/li&gt;
&lt;li&gt;ListMode: Traditional view in time line, also usually seen in other tracing system, such as Zipkin.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;error-occurred&#34;&gt;Error occurred&lt;/h3&gt;
&lt;p&gt;In the trace view, the easiest part is locating the error, possibly caused by a code exception or network fault. Both ListMode and TreeMode can identify errors, while the span detail screen provides details.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;span-error.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;ListMode error span&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;span-error-2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;TreeMode error span&lt;/p&gt;
&lt;h3 id=&#34;slow-span&#34;&gt;Slow span&lt;/h3&gt;
&lt;p&gt;A high priority feature is identifying the slowest spans in a trace. This uses execution duration captured by application agents. In the old ListMode trace view, parent span almost always includes the child span&amp;rsquo;s duration, due to nesting. In other words, a slow span usually causes its parent to also become slow. In SkyWalking 6, we provide &lt;code&gt;Top 5 of slow span&lt;/code&gt; filter to help you locate the spans directly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;top5-span.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;Top 5 slow span&lt;/p&gt;
&lt;p&gt;The above screenshot highlights the top 5 slow spans, excluding child span duration. Also, this shows all spans&#39; execution time, which helps identify the slowest ones.&lt;/p&gt;
&lt;h3 id=&#34;too-many-child-spans&#34;&gt;Too many child spans&lt;/h3&gt;
&lt;p&gt;In some cases, individual durations are quick, but the trace is still slow, like this one:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;top5-not-clear.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;Trace with no slow span&lt;/p&gt;
&lt;p&gt;To understand if the root problem is related to too many operations, use &lt;code&gt;Top 5 of children span number&lt;/code&gt;. This filter shows the amount of children each span has, highlighting the top 5.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;too-many-child.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;13 database accesses of a span&lt;/p&gt;
&lt;p&gt;In this screenshot, there is a span with 13 children, which are all Database accesses. Also, when you see overview of trace, database cost 1380ms of this 2000ms trace.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;database-long-duration.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;1380ms database accesses&lt;/p&gt;
&lt;p&gt;In this example, the root cause is too many database accesses. This is also typical in other scenarios like too many RPCs or cache accesses.&lt;/p&gt;
&lt;h3 id=&#34;trace-depth&#34;&gt;Trace depth&lt;/h3&gt;
&lt;p&gt;Trace depth is also related latency. Like the &lt;a href=&#34;#too-many-child-spans&#34;&gt;too many child spans&lt;/a&gt; scenario, each span latency looks good, but the whole trace is slow.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;deep-trace-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;Trace depth&lt;/p&gt;
&lt;p&gt;Here, the slowest spans are less than 500ms, which are not too slow for a 2000ms trace. When you see the first line, there are four different colors representing four services involved in this distributed trace. Every one of them costs 100~400ms. For all four, there nearly 2000ms. From here, we know this slow trace is caused by 3 RPCs in a serial sequence.&lt;/p&gt;
&lt;h2 id=&#34;at-the-end&#34;&gt;At the end&lt;/h2&gt;
&lt;p&gt;Distributed tracing and APM tools help users identify root causes, allowing development and operation teams to optimize accordingly. We hope you enjoyed this, and love Apache SkyWalking and our new trace visualization. If so, &lt;a href=&#34;https://github.com/apache/incubator-skywalking&#34;&gt;give us a star on GitHub&lt;/a&gt; to encourage us.&lt;/p&gt;
&lt;p&gt;SkyWalking 6 is scheduled to release at the end of January 2019. You can contact the project team through the following channels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Follow &lt;a href=&#34;https://twitter.com/ASFSkyWalking&#34;&gt;SkyWalking twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Subscribe mailing list: &lt;a href=&#34;mailto:dev@skywalking.apache.org&#34;&gt;dev@skywalking.apache.org&lt;/a&gt; . Send to &lt;a href=&#34;mailto:dev-subscribe@kywalking.apache.org&#34;&gt;dev-subscribe@kywalking.apache.org&lt;/a&gt; to subscribe the mail list.&lt;/li&gt;
&lt;li&gt;Join &lt;a href=&#34;https://gitter.im/OpenSkywalking/Lobby&#34;&gt;Gitter&lt;/a&gt; room.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
